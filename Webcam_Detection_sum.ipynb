{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Webcam Detection for traffic signs",
   "id": "36f3d9601e0d5fe9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The TSD (Traffic Signs Detection) was widely used to detect different signs shown while the vehicle is driving and to make sure the vehicle has obeyed the traffic rules. A new TSD model was trained based on a pretrained model-YOLOv8l by using a customized dataset. This dataset contains five different classes of traffic signs (U-turn, Turn left, Turn right, Go straight and Park), after training the TSD model and using mobile phone camera as a input for live testing, this model can successfully detect and classify all five kinds of traffic signs.\n",
    "\n",
    "The following shows the workflow of how to carry out the training and use mobile phone built-in camera for testing."
   ],
   "id": "7627c718bb9add99"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Step 1. Process the data",
   "id": "6424faf800b7818"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The original dataset was built to contain 1789 pictures in total. To be more specific, there were 200 pictures for the class U-turn 389 pictures for Turn right class and 400 pictures for each of the rest three classes.\n",
    "\n",
    "The dataset was been splitted into two different datasets which were the train and validation dataset to ensure the correct workflow to train the model.\n",
    "\n",
    "The following code was used to split the dataset and stored in stated direction."
   ],
   "id": "ec4c19613fbd9644"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "# Paths to dataset\n",
    "images_path = \"dataset/images\"\n",
    "labels_path = \"dataset/labels\"\n",
    "train_images_path = \"dataset_split/train/images\"\n",
    "train_labels_path = \"dataset_split/train/labels\"\n",
    "val_images_path = \"dataset_split/val/images\"\n",
    "val_labels_path = \"dataset_split/val/labels\"\n",
    "\n",
    "# Create directories for train and validation splits\n",
    "os.makedirs(train_images_path, exist_ok=True) # Use exist_ok=True to make sure no error raised when process again\n",
    "os.makedirs(train_labels_path, exist_ok=True)\n",
    "os.makedirs(val_images_path, exist_ok=True)\n",
    "os.makedirs(val_labels_path, exist_ok=True)\n",
    "\n",
    "# List all image files (end with jpg or png)\n",
    "image_files = [f for f in os.listdir(images_path) if f.endswith(('.jpg', '.png'))]\n",
    "\n",
    "# Ensure randomization of the dataset\n",
    "random.shuffle(image_files)\n",
    "\n",
    "# Split the dataset\n",
    "split_ratio = 0.8  # 80% training, 20% validation\n",
    "split_index = int(len(image_files) * split_ratio)\n",
    "train_files = image_files[:split_index]\n",
    "val_files = image_files[split_index:]\n",
    "\n",
    "\n",
    "# Copy files to their respective directories\n",
    "def copy_files(files, src_images_path, src_labels_path, dest_images_path, dest_labels_path):\n",
    "    for image_file in files:\n",
    "        # Define source and destination paths for images\n",
    "        src_image = os.path.join(src_images_path, image_file)\n",
    "        dest_image = os.path.join(dest_images_path, image_file)\n",
    "\n",
    "        # Copy the image file\n",
    "        shutil.copy(src_image, dest_image)\n",
    "\n",
    "        # Define source and destination paths for labels\n",
    "        label_file = os.path.splitext(image_file)[0] + \".txt\"  # Match the label file\n",
    "        src_label = os.path.join(src_labels_path, label_file)\n",
    "        dest_label = os.path.join(dest_labels_path, label_file)\n",
    "\n",
    "        # Check if the label file exists before copying\n",
    "        if os.path.exists(src_label):\n",
    "            shutil.copy(src_label, dest_label)\n",
    "        else:\n",
    "            print(f\"Warning: Label file not found for {image_file}\")\n",
    "\n",
    "\n",
    "# Copy the training and validation files\n",
    "copy_files(train_files, images_path, labels_path, train_images_path, train_labels_path)\n",
    "copy_files(val_files, images_path, labels_path, val_images_path, val_labels_path)\n",
    "\n",
    "print(f\"Dataset split completed! Training images: {len(train_files)}, Validation images: {len(val_files)}\")"
   ],
   "id": "e621aeeee5870e38"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Step 2. Train the model",
   "id": "38623de50202dbf1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "8f8f5ecb2f5fd772"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
